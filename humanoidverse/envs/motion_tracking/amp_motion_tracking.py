# humanoidverse/envs/motion_tracking/amp_motion_tracking.py
# åŸºäºæ ‡å‡†humanoid AMPå®ç°çš„å®Œæ•´ä¿®æ”¹ç‰ˆæœ¬

import torch
import numpy as np
from humanoidverse.envs.motion_tracking.motion_tracking import LeggedRobotMotionTracking
from isaac_utils.rotations import (
    my_quat_rotate,
    calc_heading_quat_inv,
    quat_mul,
    quat_conjugate,
    quat_rotate_inverse,
)
from humanoidverse.utils.torch_utils import quat_rotate, normalize
from loguru import logger

def quat_to_tan_norm(q):
    """
    Convert quaternion to tangent-normal form (6D representation)
    Based on the paper "On the Continuity of Rotation Representations in Neural Networks"
    """
    # Normalize quaternion
    q = normalize(q)
    
    # è·å–æ—‹è½¬çŸ©é˜µçš„å‰ä¸¤åˆ—ä½œä¸º6Dè¡¨ç¤º
    # q = [x, y, z, w] format
    w, x, y, z = q[..., 3], q[..., 0], q[..., 1], q[..., 2]
    
    # è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µçš„å‰ä¸¤åˆ—
    # First column of rotation matrix
    col1_x = 1 - 2 * (y*y + z*z)
    col1_y = 2 * (x*y + w*z)
    col1_z = 2 * (x*z - w*y)
    
    # Second column of rotation matrix  
    col2_x = 2 * (x*y - w*z)
    col2_y = 1 - 2 * (x*x + z*z)
    col2_z = 2 * (y*z + w*x)
    
    # ç»„åˆæˆ6Dè¡¨ç¤º
    col1 = torch.stack([col1_x, col1_y, col1_z], dim=-1)
    col2 = torch.stack([col2_x, col2_y, col2_z], dim=-1)
    
    return torch.cat([col1, col2], dim=-1)

class AMPMotionTracking(LeggedRobotMotionTracking):
    def __init__(self, config, device):
        # åœ¨è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ä¹‹å‰ï¼Œå…ˆä¿®å¤AMPè§‚æµ‹ç»´åº¦é…ç½®
        self._fix_amp_obs_config(config)
        
        # æ ‡è®°åˆå§‹åŒ–çŠ¶æ€
        self.init_done = False
        super().__init__(config, device)
        
        # è®¾ç½®å…³é”®èº«ä½“ç‚¹ç´¢å¼•ï¼ˆç”¨äºAMPè§‚æµ‹ï¼‰
        self._setup_key_body_ids()
        
        # æ£€æŸ¥è¯„ä¼°æ¨¡å¼çŠ¶æ€
        logger.info(f"åˆå§‹åŒ–å®Œæˆåçš„è¯„ä¼°æ¨¡å¼çŠ¶æ€: {getattr(self, 'is_evaluating', False)}")
        
        # å»¶è¿Ÿåˆå§‹åŒ–AMPæ•°æ®ï¼Œç­‰å¾… set_is_evaluating è°ƒç”¨
        self.amp_data_initialized = False
        self._init_amp_data()
        self.init_done = True

    def _fix_amp_obs_config(self, config):
        """ä¿®å¤AMPè§‚æµ‹ç»´åº¦é…ç½® - å‚è€ƒæ ‡å‡†å®ç°"""
        # è®¡ç®—æ ‡å‡†AMPè§‚æµ‹ç»´åº¦
        dof_obs_size = config.robot.dof_obs_size  # 30 for tai5
        num_key_bodies = len(config.robot.key_bodies)  # é€šå¸¸æ˜¯è„šéƒ¨å…³é”®ç‚¹
        
        # æ ‡å‡†AMPè§‚æµ‹åŒ…å«ï¼šroot_h(1) + root_rot(6) + root_vel(3) + root_ang_vel(3) + dof_obs + dof_vel + key_body_pos
        expected_amp_dim = 1 + 6 + 3 + 3 + dof_obs_size + dof_obs_size + (3 * num_key_bodies)
        
        # æ›´æ–°é…ç½®ä¸­çš„amp_obsç»´åº¦
        if "algo_obs_dim_dict" not in config.robot:
            config.robot.algo_obs_dim_dict = {}
        
        config.robot.algo_obs_dim_dict["amp_obs"] = expected_amp_dim
        
        logger.info(f"è®¾ç½®æ ‡å‡†AMPè§‚æµ‹ç»´åº¦ä¸º: {expected_amp_dim}")
        logger.info(f"ç»„æˆ: root_h(1) + root_rot(6) + root_vel(3) + root_ang_vel(3) + dof_obs({dof_obs_size}) + dof_vel({dof_obs_size}) + key_body_pos({3 * num_key_bodies})")

    def _setup_key_body_ids(self):
        """è®¾ç½®å…³é”®èº«ä½“ç‚¹ç´¢å¼•"""
        # ä½¿ç”¨è„šéƒ¨ä½œä¸ºå…³é”®èº«ä½“ç‚¹
        self._key_body_ids = self.feet_indices
        logger.info(f"è®¾ç½®å…³é”®èº«ä½“ç‚¹ç´¢å¼•: {self._key_body_ids}")

    def _init_amp_data(self):
        """åˆå§‹åŒ–AMPç›¸å…³æ•°æ®"""
        # è·å–AMPè§‚æµ‹ç»´åº¦
        amp_obs_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
        
        # AMPè§‚æµ‹ç¼“å†²åŒºï¼ˆæ€»æ˜¯éœ€è¦ï¼‰
        self.amp_obs_buf = torch.zeros(
            self.num_envs, 
            amp_obs_dim, 
            device=self.device
        )
        
        logger.info(f"åˆå§‹åŒ–AMPè§‚æµ‹ç¼“å†²åŒºï¼Œå½¢çŠ¶: {self.amp_obs_buf.shape}")
        
        # æ£€æŸ¥å½“å‰æ˜¯å¦ä¸ºè¯„ä¼°æ¨¡å¼
        is_eval = getattr(self, 'is_evaluating', False)
        logger.info(f"AMPæ•°æ®åˆå§‹åŒ–æ—¶çš„è¯„ä¼°æ¨¡å¼çŠ¶æ€: {is_eval}")
        
        if is_eval:
            logger.info("åˆå§‹åŒ–æ—¶æ£€æµ‹åˆ°è¯„ä¼°æ¨¡å¼ï¼ŒåŠ è½½expertæ•°æ®")
            self.expert_amp_loader = self._load_expert_amp_data_for_eval()
        else:
            logger.info("åˆå§‹åŒ–æ—¶ä¸ºè®­ç»ƒæ¨¡å¼ï¼ŒåŠ è½½å®Œæ•´expertæ•°æ®")
            self.expert_amp_loader = self._load_expert_amp_data_for_training()
        
        self.amp_data_initialized = True

    def _reinit_amp_for_evaluation(self):
        """é‡æ–°åˆå§‹åŒ–AMPæ•°æ®ä¸ºè¯„ä¼°æ¨¡å¼"""
        try:
            logger.info("å¼€å§‹é‡æ–°åˆå§‹åŒ–AMP expertæ•°æ®ä¸ºè¯„ä¼°æ¨¡å¼")
            
            # é‡æ–°åŠ è½½è¯„ä¼°æ¨¡å¼çš„expertæ•°æ®
            self.expert_amp_loader = self._load_expert_amp_data_for_eval()
            
            logger.info(f"âœ… AMPæ•°æ®å·²åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼Œexpertæ•°æ®å½¢çŠ¶: {self.expert_amp_loader.shape}")
            
        except Exception as e:
            logger.error(f"âŒ AMPè¯„ä¼°æ¨¡å¼é‡æ–°åˆå§‹åŒ–å¤±è´¥: {e}")
            # ä½¿ç”¨å®‰å…¨çš„fallback
            amp_obs_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
            self.expert_amp_loader = torch.zeros(100, amp_obs_dim, device=self.device)

    def _load_expert_amp_data_for_eval(self):
        """è¯„ä¼°æ¨¡å¼ï¼šåŠ è½½å°‘é‡expertæ•°æ®"""
        expert_states = []
        amp_obs_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
        
        try:
            # è¯„ä¼°æ—¶ä½¿ç”¨å‰å‡ ä¸ªmotion
            max_motions = min(3, self._motion_lib._num_unique_motions)
            samples_per_motion = 20
            
            logger.info(f"è¯„ä¼°æ¨¡å¼ï¼šåŠ è½½ {max_motions} ä¸ªmotionï¼Œæ¯ä¸ªé‡‡æ · {samples_per_motion} ä¸ªç‚¹")
            
            for motion_id in range(max_motions):
                try:
                    motion_length = self._motion_lib.get_motion_length([motion_id]).item()
                    
                    if motion_length < 0.5:
                        continue
                    
                    # å‡åŒ€é‡‡æ ·
                    for i in range(samples_per_motion):
                        time = (i / max(1, samples_per_motion - 1)) * (motion_length - 0.1)
                        
                        motion_state = self._motion_lib.get_motion_state(
                            torch.tensor([motion_id], device=self.device),
                            torch.tensor([time], device=self.device),
                            offset=torch.zeros(1, 3, device=self.device)
                        )
                        
                        amp_obs = self._build_amp_obs_from_state(motion_state)
                        expert_states.append(amp_obs)
                        
                except Exception as e:
                    logger.error(f"å¤„ç†motion {motion_id} æ—¶å‡ºé”™: {e}")
                    continue
            
            if len(expert_states) > 0:
                result = torch.stack(expert_states)
                logger.info(f"âœ… è¯„ä¼°æ¨¡å¼ï¼šæˆåŠŸåŠ è½½ {len(expert_states)} ä¸ªexpertè§‚æµ‹")
                return result
            else:
                logger.warning("âš ï¸ è¯„ä¼°æ¨¡å¼ï¼šæ²¡æœ‰åŠ è½½åˆ°expertæ•°æ®ï¼Œä½¿ç”¨fallback")
                return torch.zeros(100, amp_obs_dim, device=self.device)
                
        except Exception as e:
            logger.error(f"âŒ è¯„ä¼°æ¨¡å¼expertæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return torch.zeros(100, amp_obs_dim, device=self.device)

    def _load_expert_amp_data_for_training(self):
        """è®­ç»ƒæ¨¡å¼ï¼šåŠ è½½å¤§é‡expertæ•°æ®"""
        expert_states = []
        amp_obs_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
        
        try:
            # è®­ç»ƒæ—¶ä½¿ç”¨æ‰€æœ‰motionï¼Œå¤§é‡é‡‡æ ·
            num_motions = self._motion_lib._num_unique_motions
            samples_per_motion = 50  # å‡å°‘é‡‡æ ·ç‚¹ï¼Œé¿å…å†…å­˜é—®é¢˜
            
            logger.info(f"è®­ç»ƒæ¨¡å¼ï¼šå¤„ç† {num_motions} ä¸ªmotionï¼Œæ¯ä¸ªmotioné‡‡æ · {samples_per_motion} ä¸ªç‚¹")
            
            for motion_id in range(num_motions):
                try:
                    motion_length = self._motion_lib.get_motion_length([motion_id]).item()
                    
                    if motion_length < 0.5:  # è·³è¿‡å¤ªçŸ­çš„motion
                        logger.debug(f"Motion {motion_id} å¤ªçŸ­ ({motion_length}s)ï¼Œè·³è¿‡")
                        continue
                    
                    # å¯†é›†é‡‡æ ·æ•´ä¸ªmotion
                    for i in range(samples_per_motion):
                        # å‡åŒ€åˆ†å¸ƒé‡‡æ ·
                        time = (i / max(1, samples_per_motion - 1)) * (motion_length - 0.1)
                        
                        motion_state = self._motion_lib.get_motion_state(
                            torch.tensor([motion_id], device=self.device),
                            torch.tensor([time], device=self.device),
                            offset=torch.zeros(1, 3, device=self.device)
                        )
                        
                        amp_obs = self._build_amp_obs_from_state(motion_state)
                        expert_states.append(amp_obs)
                        
                except Exception as e:
                    logger.error(f"å¤„ç†motion {motion_id} æ—¶å‡ºé”™: {e}")
                    continue
            
            if len(expert_states) > 0:
                result = torch.stack(expert_states)
                logger.info(f"è®­ç»ƒæ¨¡å¼ï¼šæˆåŠŸåŠ è½½ {len(expert_states)} ä¸ªexpertè§‚æµ‹")
                return result
            else:
                logger.error("è®­ç»ƒæ¨¡å¼ï¼šæ²¡æœ‰åŠ è½½åˆ°ä»»ä½•expertæ•°æ®")
                return torch.zeros(1000, amp_obs_dim, device=self.device)
                
        except Exception as e:
            logger.error(f"è®­ç»ƒæ¨¡å¼expertæ•°æ®åŠ è½½è¿‡ç¨‹å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
            return torch.zeros(1000, amp_obs_dim, device=self.device)

    def _process_dof_obs(self, dof_pos):
        """å¤„ç†DOFè§‚æµ‹ - å‚è€ƒæ ‡å‡†å®ç°"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›ç›¸å¯¹äºé»˜è®¤ä½ç½®çš„åç§»
        if hasattr(self, 'default_dof_pos') and self.default_dof_pos is not None:
            return dof_pos - self.default_dof_pos.squeeze(0)
        else:
            return dof_pos

    def _build_standard_amp_obs(self, root_pos, root_rot, root_vel, root_ang_vel, 
                               dof_pos, dof_vel, key_body_pos):
        """æ ‡å‡†AMPè§‚æµ‹æ„å»ºï¼Œå‚è€ƒhumanoidå®ç°"""
        # æ ¹èŠ‚ç‚¹é«˜åº¦
        root_h = root_pos[:, 2:3]
        
        # è®¡ç®—heading rotationï¼ˆå»é™¤pitchå’Œrollï¼‰
        heading_rot = calc_heading_quat_inv(root_rot, w_last=True)
        
        # å±€éƒ¨åæ ‡ç³»ä¸‹çš„æ ¹èŠ‚ç‚¹æ—‹è½¬ï¼ˆè½¬æ¢ä¸º6Dè¡¨ç¤ºï¼‰
        local_root_rot = quat_mul(heading_rot, root_rot,w_last=True)
        root_rot_obs = quat_to_tan_norm(local_root_rot)
        
        # å±€éƒ¨åæ ‡ç³»ä¸‹çš„æ ¹èŠ‚ç‚¹é€Ÿåº¦
        local_root_vel = my_quat_rotate(heading_rot, root_vel)
        local_root_ang_vel = my_quat_rotate(heading_rot, root_ang_vel)
        
        # å±€éƒ¨åæ ‡ç³»ä¸‹çš„å…³é”®èº«ä½“ç‚¹ä½ç½®
        root_pos_expand = root_pos.unsqueeze(-2)
        local_key_body_pos = key_body_pos - root_pos_expand
        
        # è½¬æ¢å…³é”®èº«ä½“ç‚¹åˆ°å±€éƒ¨åæ ‡ç³»
        heading_rot_expand = heading_rot.unsqueeze(-2)
        heading_rot_expand = heading_rot_expand.repeat((1, local_key_body_pos.shape[1], 1))
        flat_local_key_pos = my_quat_rotate(
            heading_rot_expand.view(-1, 4), 
            local_key_body_pos.view(-1, 3)
        ).view(local_key_body_pos.shape[0], -1)
        
        # DOFè§‚æµ‹å¤„ç†
        dof_obs = self._process_dof_obs(dof_pos)
        
        # ç»„åˆæœ€ç»ˆè§‚æµ‹ - ä¸¥æ ¼æŒ‰ç…§æ ‡å‡†æ ¼å¼
        obs = torch.cat([
            root_h,                 # [B, 1] æ ¹èŠ‚ç‚¹é«˜åº¦
            root_rot_obs,          # [B, 6] å±€éƒ¨æ ¹èŠ‚ç‚¹æ—‹è½¬ï¼ˆ6Dï¼‰
            local_root_vel,        # [B, 3] å±€éƒ¨æ ¹èŠ‚ç‚¹çº¿é€Ÿåº¦  
            local_root_ang_vel,    # [B, 3] å±€éƒ¨æ ¹èŠ‚ç‚¹è§’é€Ÿåº¦
            dof_obs,              # [B, 30] å¤„ç†åçš„å…³èŠ‚ä½ç½®
            dof_vel,              # [B, 30] å…³èŠ‚é€Ÿåº¦
            flat_local_key_pos,   # [B, 6] å±€éƒ¨å…³é”®èº«ä½“ç‚¹ä½ç½®ï¼ˆ2ä¸ªè„š * 3ç»´ï¼‰
        ], dim=-1)
        
        return obs

    def _build_amp_obs_from_state(self, motion_state):
        """ä»motionçŠ¶æ€æ„å»ºæ ‡å‡†AMPè§‚æµ‹"""
        root_pos = motion_state["root_pos"][0]      # [3]
        root_rot = motion_state["root_rot"][0]      # [4] 
        root_vel = motion_state["root_vel"][0]      # [3]
        root_ang_vel = motion_state["root_ang_vel"][0]  # [3]
        dof_pos = motion_state["dof_pos"][0]        # [30]
        dof_vel = motion_state["dof_vel"][0]        # [30]
        
        # è·å–å…³é”®èº«ä½“ç‚¹
        if "rg_pos_t" in motion_state:
            all_body_pos = motion_state["rg_pos_t"][0]  # [num_bodies, 3]
            # é€‰æ‹©å…³é”®èº«ä½“ç‚¹ï¼ˆè„šéƒ¨ï¼‰
            key_body_pos = all_body_pos[self._key_body_ids]  # [num_key_bodies, 3]
        else:
            # Fallback: ä½¿ç”¨é›¶å‘é‡
            key_body_pos = torch.zeros(len(self._key_body_ids), 3, device=self.device)
        
        # æ„å»ºæ ‡å‡†AMPè§‚æµ‹
        amp_obs = self._build_standard_amp_obs(
            root_pos.unsqueeze(0),      # [1, 3]
            root_rot.unsqueeze(0),      # [1, 4]
            root_vel.unsqueeze(0),      # [1, 3] 
            root_ang_vel.unsqueeze(0),  # [1, 3]
            dof_pos.unsqueeze(0),       # [1, 30]
            dof_vel.unsqueeze(0),       # [1, 30]
            key_body_pos.unsqueeze(0)   # [1, num_key_bodies, 3]
        )
        
        return amp_obs.squeeze(0)

    def _compute_amp_observations(self):
        """è®¡ç®—å½“å‰çŠ¶æ€çš„æ ‡å‡†AMPè§‚æµ‹"""
        # è·å–å…³é”®èº«ä½“ç‚¹ä½ç½®
        if hasattr(self, '_rigid_body_pos_extend'):
            key_body_pos = self._rigid_body_pos_extend[:, self._key_body_ids, :]
        else:
            key_body_pos = self.simulator._rigid_body_pos[:, self._key_body_ids, :]
        
        # æ„å»ºæ ‡å‡†AMPè§‚æµ‹ï¼Œç¡®ä¿ä¸expertæ•°æ®æ ¼å¼å®Œå…¨ä¸€è‡´
        amp_obs = self._build_standard_amp_obs(
            self.simulator.robot_root_states[:, :3],      # root_pos [N, 3]
            self.simulator.robot_root_states[:, 3:7],     # root_rot [N, 4]
            self.simulator.robot_root_states[:, 7:10],    # root_vel [N, 3]
            self.simulator.robot_root_states[:, 10:13],   # root_ang_vel [N, 3]
            self.simulator.dof_pos,                       # dof_pos [N, 30]
            self.simulator.dof_vel,                       # dof_vel [N, 30]
            key_body_pos                                  # key_body_pos [N, num_key_bodies, 3]
        )
        
        self.amp_obs_buf[:] = amp_obs
        return amp_obs

    def get_expert_amp_observations(self, num_samples=None):
        """è·å–ä¸“å®¶AMPè§‚æµ‹ - æ”¹è¿›çš„é‡‡æ ·ç­–ç•¥"""
        if num_samples is None:
            num_samples = self.num_envs
        
        expert_data_size = len(self.expert_amp_loader)
        
        if expert_data_size == 0:
            logger.error("Expertæ•°æ®ä¸ºç©ºï¼")
            amp_obs_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
            return torch.zeros(num_samples, amp_obs_dim, device=self.device)
        
        if expert_data_size < num_samples:
            logger.debug(f"Expertæ•°æ®ä¸è¶³: {expert_data_size} < {num_samples}ï¼Œä½¿ç”¨é‡å¤é‡‡æ ·")
            # é‡å¤é‡‡æ ·
            repeats = (num_samples // expert_data_size) + 1
            expanded_data = self.expert_amp_loader.repeat(repeats, 1)
            indices = torch.randperm(len(expanded_data))[:num_samples]
            return expanded_data[indices]
        else:
            # éšæœºé‡‡æ ·
            indices = torch.randperm(expert_data_size)[:num_samples]
            return self.expert_amp_loader[indices]

    def _pre_compute_observations_callback(self):
        """åœ¨è®¡ç®—è§‚æµ‹ä¹‹å‰çš„å›è°ƒï¼Œç¡®ä¿AMPè§‚æµ‹è¢«æ›´æ–°"""
        super()._pre_compute_observations_callback()
        self._compute_amp_observations()

    def _get_obs_amp_obs(self):
        """è·å–AMPè§‚æµ‹ï¼Œç”¨äºobsç³»ç»Ÿ"""
        if not hasattr(self, 'amp_obs_buf') or self.amp_obs_buf is None:
            self._compute_amp_observations()
        return self.amp_obs_buf

    def _compute_observations(self):
        """é‡å†™è§‚æµ‹è®¡ç®—ï¼Œç¡®ä¿AMPè§‚æµ‹è¢«åŒ…å«"""
        self._compute_amp_observations()
        super()._compute_observations()

    def _init_buffers(self):
        """åˆå§‹åŒ–ç¼“å†²åŒº"""
        super()._init_buffers()
        
        # éªŒè¯AMPè§‚æµ‹ç»´åº¦
        expected_amp_dim = self.config.robot.algo_obs_dim_dict["amp_obs"]
        logger.info(f"AMPè§‚æµ‹ç»´åº¦: {expected_amp_dim}")

    def set_is_evaluating(self):
        """è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ - AMPç‰¹æ®Šå¤„ç†"""
        logger.info("ğŸ”„ AMPMotionTracking åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼")
        
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•
        super().set_is_evaluating()
        
        # é‡æ–°é…ç½®AMPæ•°æ®ä¸ºè¯„ä¼°æ¨¡å¼
        if self.amp_data_initialized:
            logger.info("é‡æ–°é…ç½®AMPæ•°æ®ä¸ºè¯„ä¼°æ¨¡å¼")
            self._reinit_amp_for_evaluation()
        else:
            logger.info("AMPæ•°æ®å°šæœªåˆå§‹åŒ–ï¼Œæ ‡è®°ä¸ºç¨åå¤„ç†")

    def _log_amp_debug_info(self):
        """è®°å½•AMPè°ƒè¯•ä¿¡æ¯"""
        if hasattr(self, 'amp_obs_buf') and hasattr(self, 'expert_amp_loader'):
            current_amp_mean = self.amp_obs_buf.mean().item()
            expert_amp_mean = self.expert_amp_loader.mean().item()
            current_amp_std = self.amp_obs_buf.std().item()
            expert_amp_std = self.expert_amp_loader.std().item()
            
            logger.debug(f"AMP Debug - Current: mean={current_amp_mean:.4f}, std={current_amp_std:.4f}")
            logger.debug(f"AMP Debug - Expert: mean={expert_amp_mean:.4f}, std={expert_amp_std:.4f}")
            logger.debug(f"AMP Debug - Expertæ•°æ®é‡: {len(self.expert_amp_loader)}")

    def _post_physics_step(self):
        """é‡å†™åå¤„ç†æ­¥éª¤ï¼Œæ·»åŠ AMPè°ƒè¯•ä¿¡æ¯"""
        super()._post_physics_step()
        
        # å®šæœŸè®°å½•AMPè°ƒè¯•ä¿¡æ¯
        if self.common_step_counter % 1000 == 0:
            self._log_amp_debug_info()
